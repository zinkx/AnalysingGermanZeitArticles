{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get vectors from data using the Natural language tool kit nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stopwords library includes all unimportant words that we don't want to take into account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "sw_de = stopwords.words('german')\n",
    "# the more recent articles contain english text\n",
    "sw_en = stopwords.words('english') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stemmer reduces words to their word stem, so that we don't count each iteration of a word as different words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"german\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get text data in list format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def prepare_data(filename):\n",
    "    with open(filename, \"r\") as read_file:\n",
    "        data = json.load(read_file)\n",
    "    wordlist = []\n",
    "    for elements in data['matches']:\n",
    "        #we don't want to vectorize the release date \n",
    "        if 'release_date' in elements:\n",
    "            del elements['release_date']\n",
    "        #sometimes teaser title and title have the same content. We don't want to count them double\n",
    "        if 'title' in elements and 'teaser_title' in elements:\n",
    "            if elements['title'] == elements['teaser_title']:\n",
    "                del elements['teaser_title']\n",
    "        #sometimes subtitle and teaser text have the same content. We don't want to count them double\n",
    "        if 'subtitle' in elements and 'teaser_text' in elements:\n",
    "            if elements['subtitle'] == elements['teaser_text']:\n",
    "                del elements['teaser_text']\n",
    "        for subelement in elements:\n",
    "            val = elements[subelement]    \n",
    "            #we want to remove numbers, since they won't be particulary telling without context\n",
    "            val = re.sub(r'[0-9\\.]+', '', val)\n",
    "            #split sentence into list of words, remove punctuation \n",
    "            words = re.sub(\"[^\\w]\", \" \",  val).split()\n",
    "            #remove all words that are stopwords \n",
    "            without_sw = [w for w in words if w.lower() not in sw_de]\n",
    "            #replace words with their stem\n",
    "            stemmed = [stemmer.stem(w) for w in without_sw]\n",
    "            stemmed = [w for w in stemmed if w not in sw_de]\n",
    "            stemmed = [w for w in stemmed if w not in sw_en]\n",
    "            #remove single letters\n",
    "            words = [w for w in stemmed if len(w)>1]\n",
    "            wordlist.append(words)\n",
    "\n",
    "    return wordlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the corresponding vectors, we use gensims Word2Vec library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1946 to 1960\n",
    "wordlist = prepare_data(\"1946_1960.json\")\n",
    "model_1946_1960 = Word2Vec(wordlist, min_count = )\n",
    "vecs_1946_1960 = model_1946_1960.wv\n",
    "vecs_1946_1960.save('vecs_1946_1960.kv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1960 to 1990\n",
    "wordlist = prepare_data(\"1960_1990.json\")\n",
    "model_1960_1990 = Word2Vec(wordlist, min_count = 5)\n",
    "vecs_1960_1990 = model_1960_1990.wv\n",
    "vecs_1960_1990.save('vecs_1960_1990.kv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1990 to 2000\n",
    "wordlist = prepare_data(\"1990_2000.json\")\n",
    "model_1990_2000 = Word2Vec(wordlist, min_count = 5)\n",
    "vecs_1990_2000 = model_1990_2000.wv\n",
    "vecs_1990_2000.save('vecs_1990_2000.kv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2000 to 2010\n",
    "wordlist = prepare_data(\"2000_2010.json\")\n",
    "model_2000_2010 = Word2Vec(wordlist, min_count = 5)\n",
    "vecs_2000_2010 = model_2000_2010.wv\n",
    "vecs_2000_2010.save('vecs_2000_2010.kv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2010 to 2021\n",
    "wordlist = prepare_data(\"2010_2021.json\")\n",
    "model_2010_2021 = Word2Vec(wordlist, min_count = 5)\n",
    "vecs_2010_2021 = model_2010_2021.wv\n",
    "vecs_2010_2021.save('vecs_2010_2021.kv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "reloaded_word_vectors = KeyedVectors.load('vecs_2010_2021.kv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('madch', 0.7156395316123962),\n",
       " ('jungfraulich', 0.6510637402534485),\n",
       " ('jahrig', 0.6335220336914062),\n",
       " ('vergewaltigt', 0.6326545476913452),\n",
       " ('mutt', 0.6281175017356873),\n",
       " ('frau', 0.595895528793335),\n",
       " ('begrapscht', 0.5917845964431763),\n",
       " ('vat', 0.5873454213142395),\n",
       " ('mannlich', 0.5871764421463013),\n",
       " ('studentin', 0.5830567479133606)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reloaded_word_vectors.most_similar('mann')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save vectors to csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = vecs_1946_1960.vectors)\n",
    "df['word']=vecs_1946_1960.index_to_key \n",
    "df=df.set_index('word')\n",
    "df.to_csv('vecs_1946_1960.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = vecs_1960_1990.vectors)\n",
    "df['word']=vecs_1960_1990.index_to_key \n",
    "df=df.set_index('word')\n",
    "df.to_csv('vecs_1960_1990.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = vecs_1990_2000.vectors)\n",
    "df['word']=vecs_1990_2000.index_to_key \n",
    "df=df.set_index('word')\n",
    "df.to_csv('vecs_1990_2000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = vecs_2000_2010.vectors)\n",
    "df['word']=vecs_2000_2010.index_to_key \n",
    "df=df.set_index('word')\n",
    "df.to_csv('vecs_2000_2010.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = vecs_2010_2021.vectors)\n",
    "df['word']=vecs_2010_2021.index_to_key \n",
    "df=df.set_index('word')\n",
    "df.to_csv('vecs_2010_2021.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connotated words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_eigenschaften ='affektiert gekünstelt geziert aggressiv angeberisch anmaßend arglistig argwöhnisch arrogant aufdringlich herablassend überheblich eingebildet boshaft cholerisch reizbar jähzornig dekadent hetzerisch dreist egozentrisch eifersüchtig einfältig eingebildet eitel elitär fies garstig großspurig herablassend hinterhältig hochmütig hysterisch ignorant intrigant langweilig manipulativ narzisstisch neurotisch oberflächlich protzig reserviert resigniert rücksichtslos scheinheilig schlampig selbstgefällig selbstgerecht selbstsüchtig selbstverliebt skrupellos spießig stur überheblich unnahbar unsozial verbohrt verlogen verschlagen versnobt willkürlich zynisch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_eigenschaften = 'Liebevoll Freundlich Bescheiden Respektvoll Aufrecht Sorgfältig Nett Ambitioniert Zielbewusst Ehrlich Verlässlich Gerecht Mutig Warmherzig Intelligent Sympathisch Geduldig Beständig Ordentlich Präzise Hilfsbereit Kommunikativ Selbstbewusst Mutig Vernünftig Flexibel Ehrgeizig Verantwortlich Demütig Friedliebend Sensibel Aktiv Ausgeglichen Witzig Angenehm Attraktiv Anpassungsfähig Arbeitsam Empfindlich Sachlich Heroisch Unterhaltsam Schön Kreativ Erfinderisch Verantwortungsbewusst Schlau Gutmütig Lustig Bescheiden'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_eigenschaften = negative_eigenschaften.split()\n",
    "stemmed_NEG = [stemmer.stem(w) for w in negative_eigenschaften]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_eigenschaften = positive_eigenschaften.split()\n",
    "stemmed_POS = [stemmer.stem(w) for w in positive_eigenschaften]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adjectives = pd.DataFrame()\n",
    "df_adjectives['pos'] = stemmed_POS \n",
    "df_adjectives['neg'] = stemmed_NEG[:50]\n",
    "df_adjectives.to_csv('adjectives.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
